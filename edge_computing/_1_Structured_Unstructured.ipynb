{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0GW5L5IEXB4a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load CIFAR-10 Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sz-HfyJXCeh",
        "outputId": "61aaef35-aa00-44dd-c6ee-58db42d7da17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition (using the previously defined ComplexCNN)\n",
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexCNN, self).__init__()\n",
        "\n",
        "        # Conv Blocks\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dummy FC layer (to be replaced)\n",
        "        self.fc1 = None\n",
        "\n",
        "        # Calculate FC input size dynamically\n",
        "        self._initialize_fc()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "\n",
        "        # Flatten for FC layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten to [batch_size, features]\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_fc(self):\n",
        "        # Pass a dummy input to calculate FC input size\n",
        "        dummy_input = torch.zeros(1, 3, 32, 32)  # CIFAR-10 input size\n",
        "        x = self.pool1(F.relu(self.conv1(dummy_input)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        fc_input_size = x.view(x.size(0), -1).size(1)\n",
        "        self.fc1 = nn.Linear(fc_input_size, 10)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6U1kZx9XcGz9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning Methods\n",
        "def apply_structured_pruning(model, amount=0.5):\n",
        "    \"\"\"\n",
        "    Applies structured pruning to the model by pruning entire filters.\n",
        "    \"\"\"\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            prune.ln_structured(module, name='weight', amount=amount, n=2, dim=0)  # 수정된 부분\n",
        "\n",
        "def apply_unstructured_pruning(model, amount=0.5):\n",
        "    \"\"\"\n",
        "    Applies unstructured pruning to the model by pruning individual weights.\n",
        "    \"\"\"\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "            torch.nn.utils.prune.random_unstructured(module, name='weight', amount=amount)\n",
        "\n"
      ],
      "metadata": {
        "id": "3MqEj5jzcJSa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function\n",
        "def evaluate_model(model, data_loader):\n",
        "    \"\"\"\n",
        "    Measures accuracy and inference time for a given model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    inference_time = time.time() - start_time\n",
        "    accuracy = 100 * correct / total\n",
        "    return inference_time, accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "LXyOj-VhcMAB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function (to fine-tune pruned models)\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "# Main Comparison\n",
        "original_model = ComplexCNN().to(device)\n",
        "\n",
        "# Pretrained model loading (if available)\n",
        "# torch.save(original_model.state_dict(), \"original_cnn.pt\")\n",
        "# original_model.load_state_dict(torch.load(\"original_cnn.pt\"))\n",
        "\n",
        "# Optimizer and loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(original_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the original model (if not pre-trained)\n",
        "train_model(original_model, train_loader, criterion, optimizer, epochs=3)\n",
        "\n",
        "# Clone the model for pruning\n",
        "structured_pruned_model = ComplexCNN().to(device)\n",
        "unstructured_pruned_model = ComplexCNN().to(device)\n",
        "\n",
        "structured_pruned_model.load_state_dict(original_model.state_dict())\n",
        "unstructured_pruned_model.load_state_dict(original_model.state_dict())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na8LiXQ1cONP",
        "outputId": "b43090ae-17a1-4419-df41-3c9f66a69311"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Pruning\n",
        "apply_structured_pruning(structured_pruned_model, amount=0.5)\n",
        "apply_unstructured_pruning(unstructured_pruned_model, amount=0.5)\n",
        "\n",
        "# Fine-tune Pruned Models\n",
        "structured_optimizer = optim.Adam(structured_pruned_model.parameters(), lr=0.001)\n",
        "unstructured_optimizer = optim.Adam(unstructured_pruned_model.parameters(), lr=0.001)\n",
        "\n",
        "train_model(structured_pruned_model, train_loader, criterion, structured_optimizer, epochs=3)\n",
        "train_model(unstructured_pruned_model, train_loader, criterion, unstructured_optimizer, epochs=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "q32k5QNhcT7-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Models\n",
        "results = []\n",
        "for i in range(5):  # Perform multiple evaluation iterations\n",
        "    print(f\"Iteration {i+1}/5\")\n",
        "\n",
        "    original_time, original_accuracy = evaluate_model(original_model, test_loader)\n",
        "    structured_time, structured_accuracy = evaluate_model(structured_pruned_model, test_loader)\n",
        "    unstructured_time, unstructured_accuracy = evaluate_model(unstructured_pruned_model, test_loader)\n",
        "\n",
        "    results.append({\n",
        "        \"Iteration\": i + 1,\n",
        "        \"Original_Inference_Time\": original_time,\n",
        "        \"Original_Accuracy\": original_accuracy,\n",
        "        \"Structured_Inference_Time\": structured_time,\n",
        "        \"Structured_Accuracy\": structured_accuracy,\n",
        "        \"Unstructured_Inference_Time\": unstructured_time,\n",
        "        \"Unstructured_Accuracy\": unstructured_accuracy,\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xAhV7tEcVvY",
        "outputId": "a0a7fdb9-8dfd-4aa4-dc73-31f59538ad3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/5\n",
            "Iteration 2/5\n",
            "Iteration 3/5\n",
            "Iteration 4/5\n",
            "Iteration 5/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and compute statistics\n",
        "df = pd.DataFrame(results)\n",
        "df['Original_Time_Mean'] = df['Original_Inference_Time'].mean()\n",
        "df['Original_Accuracy_Mean'] = df['Original_Accuracy'].mean()\n",
        "df['Structured_Time_Mean'] = df['Structured_Inference_Time'].mean()\n",
        "df['Structured_Accuracy_Mean'] = df['Structured_Accuracy'].mean()\n",
        "df['Unstructured_Time_Mean'] = df['Unstructured_Inference_Time'].mean()\n",
        "df['Unstructured_Accuracy_Mean'] = df['Unstructured_Accuracy'].mean()\n",
        "\n",
        "df.to_csv(\"pruning_comparison.csv\", index=False)\n",
        "print(\"Results saved to pruning_comparison.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mOAusV2cXVZ",
        "outputId": "b20e7ecd-6cb6-4d45-a1d6-a92411d93f61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to pruning_comparison.csv\n"
          ]
        }
      ]
    }
  ]
}